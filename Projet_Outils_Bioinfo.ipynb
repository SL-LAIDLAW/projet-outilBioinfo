{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet Outils Bioinfo",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SL-LAIDLAW/projet-outilBioinfo/blob/dev/Projet_Outils_Bioinfo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "I9tXaxrcF3xh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Projet de HMSN204\n",
        "_Sean LAIDLAW_, _Mathieu Blaison_"
      ]
    },
    {
      "metadata": {
        "id": "klJRV24iHyS1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Traitements Biopython de SEX1"
      ]
    },
    {
      "metadata": {
        "id": "pM35FjxJJbEg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Obtention des sequences sauvages et mutés, du NCBI"
      ]
    },
    {
      "metadata": {
        "id": "DyW-01BAyTDS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Obtention du sequence sauvage"
      ]
    },
    {
      "metadata": {
        "id": "kjnQ9cvMDwHg",
        "colab_type": "code",
        "outputId": "0c87fbcc-da20-42c1-e0d0-fb3f7f12d0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install biopython\n",
        "!pip install pandas\n",
        "from Bio import SeqIO \n",
        "from Bio import Entrez"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.6/dist-packages (1.73)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.14.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "acLms62_0yOM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "À partir de TAIR, on a obtenu l'identifiant correspondant au *full length cDNA* de la sequence genomique de SEX1. Un requete envers la base de donnée nucleotide du NCBI nous a fourni le fasta de cette sequence."
      ]
    },
    {
      "metadata": {
        "id": "IYn0Q2Roycdi",
        "colab_type": "code",
        "outputId": "379da3bf-b242-486a-f532-4b008c8e31cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "Entrez.email = \"sean.laidlaw@etu.umontpellier.fr\"\n",
        "seqgb  = Entrez.efetch (db=\"nucleotide\",id='NM_001331926.1', rettype='fasta')\n",
        "seqselect = SeqIO.parse(seqgb, \"fasta\")\n",
        "\n",
        "sex1_sauvage = []\n",
        "for sequence in seqselect:\n",
        "    sex1_sauvage = sequence.seq\n",
        "sex1_sauvage\n",
        "print(sex1_sauvage)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TATCTTCTGCAATTCGTGGTTTGTGAACACAAGAGAAAAAAAAAAAAAAACATAAAAAAGAAAGAAAAATTAAAAAAAGCTAAAATCAACGGTGAGAAGATTCTGTATATAATAAGAAAATATCACCCAAATAAAAAAAAAAGGTGGAGTCCACAGATACCGTCCATCAACGTATCACTGGGCTCTCTTTCTCCGTGCCGTTCCTCCTACGTGCTCGAATAACGATGTGCCACGTGGTGGAATCGAAGGATAAAGTGTCGTTTTTTACTTCGATTACACGTGAGTGTATGTATGTGTGAGTGAGTGAAGAAGAACAAAGAGCGAAGAAACCCCCCAGCACTCACTTCATCCATAAGATCATTCAAATTCTGGGATCTTCTCTCTTTCTCTCATTGTATTCAGTTTCTTCGTCTCGGTTCGATCATCAGATCCGGCAAGTTTGATTCAGTGACAAGAAAGCATGAGTAACTCTGTAGTGCATAACTTACTTAACCGGGGTTTGATTCGTCCTCTTAACTTTGAACATCAAAACAAGCTCAACTCCTCTGTGTACCAAACTTCAACAGCAAATCCGGCTCTTGGCAAGATTGGCAGATCAAAACTTTACGGGAAAGGTCTTAAGCAGGCAGGACGCAGTCTGGTCACTGAAACAGGAGGAAGACCTCTCTCATTTGTTCCACGAGCTGTCCTTGCCATGGATCCTCAGGCAGCCGAGAAATTTAGTCTTGACGGAAATATCGATTTACTGGTTGAAGTCACTTCTACAACTGTAAGAGAAGTAAATATCCAGATAGCTTATACAAGTGACACATTGTTCCTACACTGGGGTGCAATTCTTGACAACAAAGAAAATTGGGTTCTACCTTCTCGCTCTCCGGATAGAACTCAAAACTTCAAGAACAGTGCGCTTAGAACTCCATTTGTGAAATCCGGTGGCAATTCTCACCTTAAACTAGAGATAGATGATCCTGCCATACACGCTATTGAGTTCCTTATATTTGACGAAAGTCGGAACAAATGGTATAAAAATAATGGTCAGAATTTTCATATAAACTTACCAACGGAAAGGAATGTGAAACAAAATGTTTCTGTTCCTGAAGATCTTGTACAGATCCAAGCATATCTTAGATGGGAACGTAAGGGTAAACAAATGTACAACCCTGAGAAAGAGAAGGAGGAGTATGAAGCCGCCCGGACGGAGCTACGGGAGGAAATGATGCGAGGTGCTTCAGTGGAAGATCTCAGAGCAAAGCTGTTGAAGAAAGATAACAGTAATGAATCCCCAAAATCTAATGGGACATCATCCAGTGGACGGGAGGAAAAGAAAAAAGTTTCCAAGCAACCAGAGCGTAAAAAAAATTATAACACTGACAAGATCCAGCGCAAGGGAAGGGACCTGACTAAGCTTATCTATAAGCATGTTGCTGATTTTGTTGAACCAGAATCCAAATCCTCATCTGAACCACGGTCCTTAACAACTCTGGAGATATACGCCAAAGCAAAGGAGGAACAAGAAACCACTCCAGTCTTTAGCAAGAAAACATTCAAGCTTGAAGGCAGTGCGATTTTGGTGTTTGTTACTAAACTTTCCGGAAAGACGAAAATTCATGTGGCAACTGATTTTAAAGAGCCGGTTACCCTTCACTGGGCTTTGTCTCAAAAGGGTGGAGAATGGTTGGACCCACCTTCAGATATACTGCCACCAAACTCTTTGCCAGTACGTGGTGCTGTTGATACAAAACTGACCATCACTTCAACAGATCTTCCTAGTCCGGTTCAAACTTTTGAGCTGGAAATAGAAGGTGACAGCTACAAGGGCATGCCGTTTGTACTCAATGCTGGTGAAAGGTGGATTAAAAATAATGACAGTGACTTTTATGTGGACTTTGCTAAAGAAGAAAAACATGTTCAGAAGGATTATGGCGATGGAAAGGGTACAGCCAAGCATTTACTGGACAAAATCGCAGATTTGGAGAGTGAGGCCCAGAAGTCTTTCATGCATCGATTCAACATTGCAGCAGATCTTGTGGACGAGGCAAAAAGTGCTGGTCAACTGGGCTTTGCAGGGATCCTAGTCTGGATGAGGTTTATGGCTACAAGACAGCTTGTGTGGAACAAAAACTATAATGTTAAGCCAAGGGAGATAAGCAAAGCGCAGGATAGACTGACTGACCTTCTCCAGGACGTTTATGCAAGTTATCCAGAGTACAGAGAACTTTTGCGGATGATAATGTCTACTGTAGGTCGAGGAGGTGAAGGAGATGTCGGGCAACGAATCCGTGACGAAATTCTAGTCATCCAGCGGAAAAATGACTGCAAGGGTGGAATTATGGAGGAATGGCATCAGAAGTTGCATAACAACACTAGTCCAGATGATGTTGTCATCTGTCAGGCATTGATGGATTATATCAAAAGTGACTTTGACTTAAGTGTTTACTGGAAGACCTTGAACGATAATGGCATAACCAAAGAGCGACTCTTAAGTTATGATCGTGCTATACATTCTGAACCAAATTTTAGAGGAGAACAAAAAGACGGTCTTTTGCGTGATCTTGGACACTACATGAGGACTTTAAAGGCTGTTCATTCAGGGGCAGACCTTGAGTCGGCTATACAAAATTGCATGGGCTACCAAGATGACGGTGAAGGTTTCATGGTTGGGGTGCAGATAAATCCTGTATCAGGATTGCCTTCTGGATATCCAGACTTGCTTCGTTTCGTCCTAGAACATGTTGAAGAAAAGAATGTAGAGCCACTTCTTGAGGGTTTGCTTGAAGCTCGTCAAGAGCTAAGGCCACTTCTGCTGAAGTCCCATGACCGCCTCAAGGATCTGTTATTCTTGGACCTCGCTCTTGATTCTACTGTCAGAACAGCGATTGAAAGAGGATATGAGCAATTGAATGATGCTGGACCTGAGAAAATCATGTACTTCATCAGCCTAGTTCTTGAAAATCTTGCCCTCTCTTCAGATGACAATGAAGACCTTATATACTGCTTGAAGGGATGGCAATTTGCCCTCGACATGTGCAAGAGCAAAAAAGATCACTGGGCTCTGTATGCAAAATCTGTTCTTGACAGAAGCCGACTAGCACTGGCAAGCAAAGCTGAGAGGTACCTTGAAATTCTGCAACCATCGGCTGAATATCTTGGATCTTGTCTTGGAGTCGATCAGTCGGCTGTTAGTATATTTACTGAAGAGATCATTCGAGCTGGATCTGCAGCAGCATTGTCGTCACTTGTTAACCGACTTGACCCAGTTCTTAGGAAGACTGCTAACTTGGGAAGTTGGCAGGTTATTAGTCCTGTAGAGGTCGTCGGATATGTCATTGTTGTGGACGAATTGCTCACTGTACAGAATAAAACCTACGATAGACCTACAATTATAGTTGCAAACAGAGTGAGAGGAGAGGAGGAAATCCCTGATGGTGCAGTTGCGGTACTGACACCTGACATGCCGGATGTACTATCTCATGTTTCTGTTCGAGCAAGAAATGGAAAGATCTGCTTTGCCACATGTTTTGATTCTGGTATCTTATCTGACCTCCAAGGAAAAGATGGAAAACTGTTGAGCCTACAACCAACCTCTGCAGATGTAGTCTATAAAGAGGTAAACGATAGTGAGCTTTCGAGTCCAAGTTCAGACAACCTGGAAGATGCCCCTCCAAGTATTTCTTTGGTCAAGAAACAGTTTGCGGGTAGATATGCTATATCATCTGAGGAGTTCACAAGTGACTTGGTTGGTGCTAAATCAAGAAATATCGGGTATCTGAAAGGAAAAGTTCCTTCTTGGGTTGGTATCCCAACTTCAGTTGCGTTGCCATTTGGTGTTTTTGAGAAGGTTATCTCCGAAAAGGCGAATCAGGCGGTGAACGATAAATTGCTAGTATTGAAGAAAACTCTTGATGAGGGAGACCAAGGTGCTCTGAAGGAAATCCGGCAGACACTGTTGGGGCTAGTTGCACCCCCAGAACTGGTTGAAGAACTGAAAAGTACTATGAAAAGTTCTGACATGCCATGGCCGGGTGATGAAGGTGAACAGAGATGGGAGCAAGCTTGGGCAGCCATTAAAAAGGTCTGGGCTTCGAAATGGAACGAGAGAGCATACTTCAGCACGAGGAAAGTAAAACTGGATCATGACTATCTCTGCATGGCTGTTTTGGTCCAAGAAGTCATCAATGCGGATTACGCATTCGTCATTCACACAACTAATCCATCTTCTGGAGATTCATCAGAGATTTATGCCGAGGTGGTCAAAGGCCTTGGGGAAACTCTTGTAGGAGCATATCCCGGTCGGTCTCTGAGTTTCATCTGCAAGAAAAACAACCTTGATTCGCCTCTGGTGTTGGGCTACCCAAGCAAACCGATTGGGCTGTTCATAAGACGTTCAATCATCTTCAGATCTGATTCCAATGGAGAAGATCTTGAAGGTTATGCAGGTGCAGGCCTCTACGACAGTGTACCAATGGACGAGGAAGACCAAGTCGTGCTCGATTACACAACAGATCCTCTGATCACTGACTTGAGCTTCCAGAAAAAGGTTCTCTCAGACATTGCACGCGCTGGAGATGCCATTGAGAAACTCTATGGAACTGCACAGGACATTGAAGGTGTGATCAGAGACGGGAAGCTCTATGTCGTCCAGACACGACCACAAGTGTGATCAAATTCTCTGACCACTTCTTAATGTGTACGTTACGTTTTCTGTCCAGTAAACTCCTTATTTGCTCTATAAGCAAAGAGTATAATACAGCATAAGCATATAGTGGATTACAAAATGTGTAGTACAAAGACATTTGGCATTACCATTAAGATATAAATAAAAAAACTGTTTATTGGAGTTGGAAGTTTCTCCAGCTTTTGCTTCTTGAAGTTGAGTGCAACTGAAAACTGCTTGTCGTTTCACTGGTCGAGCGATATGACTACTTAGTGTTTGGCTTTTGTGAATTAGTGACTCAACTGTATTCCCAATTCAAATTAGGGTCTAAATTGTAATAAAATATAGATAATGTTTCCTTTTTTCCTGAATAATTTTCTTTTAAG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M4wyFCjVyZui",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Obtention de la sequence muté"
      ]
    },
    {
      "metadata": {
        "id": "8dOvKpryJdUf",
        "colab_type": "code",
        "outputId": "0bcb2148-0f37-40da-fc53-09d3b16cd462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "search_string = \"SEX1[Gene] AND Arabidopsis thaliana[Organism]\"\n",
        "req = Entrez.esearch(db= \"nucleotide\", term=search_string)  # ID of fasta of SEX1 gene\n",
        "res = Entrez.read(req)\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictElement({'Count': '5', 'RetMax': '5', 'RetStart': '0', 'IdList': ['1063682343', '1063682341', '334182442', '240254421', '332189094'], 'TranslationSet': [DictElement({'From': 'Arabidopsis thaliana[Organism]', 'To': '\"Arabidopsis thaliana\"[Organism]'}, attributes={})], 'TranslationStack': [DictElement({'Term': 'SEX1[Gene]', 'Field': 'Gene', 'Count': '8', 'Explode': 'N'}, attributes={}), DictElement({'Term': '\"Arabidopsis thaliana\"[Organism]', 'Field': 'Organism', 'Count': '2696552', 'Explode': 'Y'}, attributes={}), 'AND'], 'QueryTranslation': 'SEX1[Gene] AND \"Arabidopsis thaliana\"[Organism]'}, attributes={})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "1ngkHoIIwgcx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ici on voit que les seules fasta disponible sont des variants d'epissage alternative, et vu que l'aligneur que nous allons construire ne va pas  être *splice-aware* , on aura des problèmes quand leurs introns n'aligneront pas avec notre sequence sauvage.\n",
        "\n",
        "Importons alors, un version du SEX1 sauvage modifié afin de presenter 1/4 des SNP enregistré sur dbSNP pour ce gène:"
      ]
    },
    {
      "metadata": {
        "id": "6fXvEugyZfm2",
        "colab_type": "code",
        "outputId": "f3c15e8d-9ff5-4801-cd86-e7c7183741f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import urllib.request  # the lib that handles the url stuff\n",
        "from Bio.Seq import Seq\n",
        "data = urllib.request.urlopen('https://raw.githubusercontent.com/SL-LAIDLAW/projet-outilBioinfo/dev/sex1_mutant_SNP.fasta') # it's a file like object and works just like a file\n",
        "sex1_mutant = data.read()\n",
        "sex1_mutant = sex1_mutant.decode('utf8').split('\\n')[1:]\n",
        "sex1_mutant = \"\".join(sex1_mutant)\n",
        "\n",
        "sex1_mutant = Seq(sex1_mutant)\n",
        "sex1_mutant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq('TATCTTCTGCAATTCGTGGTTTGTGAACACAAGAGAAAAAAAAAAAAAAACATA...AAG')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "IHXayGwfJRm-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Alignement des séquences associées aux gènes sauvages/mutés"
      ]
    },
    {
      "metadata": {
        "id": "Tfj0bgKE0deU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### un alignement par paire global des séquences d’ARNm"
      ]
    },
    {
      "metadata": {
        "id": "LUlSZdPPum9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pour aligner nos sequences sauvages avec les mutants nous avons ecrit la fonction AlignSeqs qui effectue un alignement globale en utilisant l'algorithme Needleman–Wunsch."
      ]
    },
    {
      "metadata": {
        "id": "Y7TMFq91rMay",
        "colab_type": "code",
        "outputId": "19eeb163-23fd-4924-a9b9-678214a2ca78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install cython\n",
        "%load_ext Cython"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mMothTUXGv9C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " %%cython\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a-I6VY5cGRHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def InitializeTable(SeqX,SeqY):\n",
        "  # intitialise dataframe holding scores\n",
        "  df = pd.DataFrame(index=SeqY, columns=SeqX)\n",
        "  col_names = list(df.keys())\n",
        "  row_names = list(df.index)\n",
        "\n",
        "  # initiate table\n",
        "  df.iloc[0,0] = 0\n",
        "  for i in range(len(SeqY)):\n",
        "    df.iloc[i,0] = i * -1  # set row 0 to be -1,-2,-3\n",
        "  for i in range(len(SeqX)):\n",
        "    df.iloc[0,i] = i * -1  # set col 0 to be -1,-2,-3\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rs76f3PaGSgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%cython\n",
        "def PopulateTable(seqX,seqY,df):     \n",
        "  df_dir = df.copy()\n",
        "  # populate table\n",
        "  for y in range(1,len(seqY)):\n",
        "    for x in range(1,len(seqX)):\n",
        "      current_score = -1000\n",
        "      \n",
        "      match_score = 1\n",
        "      mismatch_score = -1\n",
        "\n",
        "      if str(seqX[x]) == str(seqY[y]):\n",
        "        current_score = match_score\n",
        "      else:\n",
        "        current_score = mismatch_score\n",
        "\n",
        "      df.iloc[y,x] = current_score\n",
        "\n",
        "      top_left_score = ((df.iloc[y-1,x-1]), '\\x5C')\n",
        "      top_score = ((df.iloc[y-1,x]), '\\x7C')\n",
        "      left_score = ((df.iloc[y,x-1]), '\\x3C')\n",
        "\n",
        "      best_score = top_score[0]\n",
        "      best_direction = top_score[1]\n",
        "      score_list = [top_left_score, top_score, left_score]\n",
        "      for score_item in score_list:\n",
        "        if int(score_item[0]) > int(best_score):\n",
        "          best_direction = score_item[1]\n",
        "          best_score = score_item[0]\n",
        "\n",
        "        elif int(score_item[0]) == int(best_score):\n",
        "          if not best_direction.__contains__(score_item[1]):\n",
        "            best_direction += score_item[1]\n",
        "\n",
        "      # delete score objects from memory as this caused issues\n",
        "      for score in score_list:\n",
        "        del score\n",
        "\n",
        "      best_score = int(best_score)\n",
        "      best_score += current_score\n",
        "\n",
        "      df.iloc[y,x] = best_score\n",
        "      df_dir.iloc[y,x] = best_direction\n",
        "  return df, df_dir  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "91mEYJ0nGXcy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Traceback(df,df_dir):\n",
        "    # Start traceback\n",
        "    my_alignment_x =[]\n",
        "    my_alignment_y =[]\n",
        "    bottom_right_y = list(df.shape)[0] -1\n",
        "    bottom_right_x = list(df.shape)[1] -1\n",
        "\n",
        "    x = bottom_right_x\n",
        "    y = x - (bottom_right_x - bottom_right_y)\n",
        "    while x != 0:\n",
        "      current_coordinates = [y,x]\n",
        "      top_coordinates = [y-1,x]\n",
        "      left_coordinates = [y,x-1]\n",
        "      top_left_coordinates = [y-1,x-1]\n",
        "\n",
        "      current_nucleotide_x = df.keys()[x]\n",
        "      current_nucleotide_y = df.index[y]\n",
        "      current_direction = df_dir.iloc[y,x]\n",
        "\n",
        "      if current_direction.__contains__('\\\\'):\n",
        "        # move coordinates to top_left\n",
        "        x = top_left_coordinates[1]\n",
        "        y = top_left_coordinates[0]\n",
        "        my_alignment_x.append(current_nucleotide_x)\n",
        "        my_alignment_y.append(current_nucleotide_y)\n",
        "\n",
        "      elif current_direction.__contains__('|'):\n",
        "        # move coordinates to top\n",
        "        x = top_coordinates[1]\n",
        "        y = top_coordinates[0]\n",
        "        my_alignment_x.append('-')\n",
        "        my_alignment_y.append(current_nucleotide_y)\n",
        "\n",
        "      elif current_direction.__contains__('<'):\n",
        "        # move coordinates to left\n",
        "        x = left_coordinates[1]\n",
        "        y = left_coordinates[0]\n",
        "        my_alignment_x.append(current_nucleotide_x)\n",
        "        my_alignment_y.append('-')\n",
        "        \n",
        "      return my_alignment_x, my_alignment_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJJo9uZdGbe3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def GetVariations(my_alignment_x, my_alignment_y):\n",
        "  points_de_variations = set()\n",
        "  for i in range(len(my_alignment_x)):\n",
        "    x = my_alignment_x[i]\n",
        "    y = my_alignment_y[i]\n",
        "\n",
        "    if x != y:\n",
        "      points_de_variations.add(i)\n",
        "  return list(points_de_variations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XourqqJz6gTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def AlignSeqs(SeqX,SeqY):\n",
        "  SeqX = list(\" \" + SeqX)\n",
        "  SeqY = list(\" \" + SeqY)\n",
        "\n",
        "  match_score = 1\n",
        "  mismatch_score = -1\n",
        "  indel_score = -1\n",
        "  \n",
        "  penaltyArgs=[match_score, mismatch_score, indel_score]\n",
        "\n",
        "  df = InitializeTable(SeqX,SeqY)\n",
        "\n",
        "  df, df_dir = PopulateTableJit(SeqX,SeqY,df)\n",
        "\n",
        "\n",
        "  my_alignment_x, my_alignment_y = Traceback(df,df_dir)\n",
        "\n",
        "  my_alignment_x.reverse()\n",
        "  my_alignment_y.reverse()\n",
        "\n",
        "  points_de_variations = GetVariations(my_alignment_x, my_alignment_y)\n",
        "\n",
        "\n",
        "  return my_alignment_x, my_alignment_y, points_de_variations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ucz2s3Wrh8sm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cet étape prends beaucoup de temps donc est commenté pour l'instant"
      ]
    },
    {
      "metadata": {
        "id": "2024QNyL2IVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result_dict = {}\n",
        "alignment_for_mutant, alignment_for_sauvage, variations = AlignSeqs(sex1_mutant, sex1_sauvage)\n",
        "result_dict[mutant] = [alignment_for_mutant, alignment_for_sauvage, variations]\n",
        "\n",
        "%store result_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jRIxcNmg0e3N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### donner les positions des variations sauvage/muté"
      ]
    },
    {
      "metadata": {
        "id": "pfB_Rb0a0zUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%store -r result_dict  # loads saved result from cache instead of re-running command\n",
        "\n",
        "for key in result_dict.keys():\n",
        "  result_list = result_dict[key]\n",
        "  variants = result_list[2]\n",
        "  for var in variants:\n",
        "    print(var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D6cPw4Xe00aL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### taux de GC / traduction pour obtenir les séquences protéiques"
      ]
    },
    {
      "metadata": {
        "id": "Tj71epn-0ib2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from Bio.SeqUtils import GC\n",
        "from Bio.Seq import Seq\n",
        "\n",
        "taux_GC_sauvage = GC(sex1_sauvage)\n",
        "print(taux_GC_sauvage)\n",
        "taux_GC_mutant = GC(sex1_mutant)\n",
        "print(taux_GC_mutant)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "24hGHJfn4lvR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "from Bio import AlignIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqUtils import GC\n",
        "from Bio import SeqIO\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "\n",
        "\n",
        "trans_sauvage = sex1_sauvage.translate()\n",
        "trans_mutant = sex1_mutant.translate()\n",
        "\n",
        "print(trans_sauvage)\n",
        "print(trans_mutant)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1huvEa5Dv4W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Base de données"
      ]
    },
    {
      "metadata": {
        "id": "CIXoEEVLEWO0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reflexion sur le type de base de données"
      ]
    },
    {
      "metadata": {
        "id": "6eRl6EBaEaNG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On a eu le choix d’un des SGBD vu ce semestre : chado/postgresql (module phenotype), relationnel seul (oracle, postgresqlou mysql), neo4j, couchdb, triplestore jena/rdf. \n",
        "\n",
        "On a choisi d'eviter les base de données NoSQL car nous avons plus d'experience avec ceux là. \n",
        "\n",
        "Notre choix s'est ainsi  porté sur la base de données Chado. Celle-ci est conçue spécialement pour gérer les représentations complexes de données biologiques. Chado va également posséder des modules permettant de gérer spécifiquement les relations entre termes ontologiques. Pour créer sa base de données Chado utilise le système  de gestion PostgreSQL. Ayant deja des bases en SQL , ce choix nous a ainsi paru judicieux  pour pouvoir réaliser une implémentation correcte de la base de données avec un temps limité et la taille de notre groupe."
      ]
    },
    {
      "metadata": {
        "id": "K41fxSetDz9m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modelisation de la base de données"
      ]
    },
    {
      "metadata": {
        "id": "kstiJ-1T6bck",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Avant de nous lancer dans la création de notre base de donnée il faut d'abord la penser. Pour ce faire le meilleur moyen est de se représenter la base de données visuellement à l'aide d'un shéma UML et plus particulièrement d'un diagramme de classes. Notre bases de données se divise en \"deux\" parties. Une gérant les données issues des expérimentations des M1 BFP et l'autre gérant les termes d'ontologies. Un lien est fait entre ces 2 parties au niveau de la table phénotype. Avec le recul cette manière de faire n'était probablement pas la meilleure et des améliorations doivent être apportés principalement pour la partie gérant l'ontologie.\n",
        "\n",
        "\n",
        "Nous retrouvons ansi avec une base de données corrspondant au diagramme de classe suivant:"
      ]
    },
    {
      "metadata": {
        "id": "aL2vyUpZ6pLF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Diagramme de Classe](https://raw.githubusercontent.com/SL-LAIDLAW/projet-outilBioinfo/dev/class_diagramm.pdf)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0RT-DruKFdkB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ontologie"
      ]
    },
    {
      "metadata": {
        "id": "jNsI08EqFiMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il a ainsi fallu penser à la manière d'intégrer l'ontologie dans notre base de données  . L'ontologie va représenter des concepts (comme une caractéristique phénotypique)   et les relations que ces concepts peuvent partager.  Dans notre cas on s'est intéressé à rechercher les relations entre les termes ontologiques constituant les phénotypes observés et mesurés par les étudiants BFP.  Pour ce faire ces phénotypes ont été \"décomposé\"  en plusieurs et leur terme ontologique ont été associé en une relation. Par exemple, la longueur de la racine primaire va corrrespondre à une longueur de racine (possédant son terme ontologique) qui ferait partie (is part of) d'une racine primaire(possédant aussi son propre terme ontologique).  ces données générées seront ensuite insérées dans notre base de données. Ces données peuvent être récupérées grâce à de nombreuses ressources regroupant les termes d'ontologies appartenant à un même \"groupe\". "
      ]
    },
    {
      "metadata": {
        "id": "MlL_6PJtHjNB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implantation de la base de données et peuplement"
      ]
    },
    {
      "metadata": {
        "id": "mzBJmNDvzCCq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kG1ZVskc1xo1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/SL-LAIDLAW/projet-outilBioinfo/master/Data_Projet_Entete.csv\",sep=\";\")\n",
        "df['Mutant'] = False\n",
        "df['Mutant'].loc[df['Genotype'] != \"Col_0\"] = True\n",
        "df.loc[df['Mutant'] == True]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pU8CxuMK2TEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cov = df.cov()\n",
        "cov"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsrF0az4S3fR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Création des tables"
      ]
    },
    {
      "metadata": {
        "id": "tF4Im5IiTYuG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Afin de créer les tables un script SQL de création de ces tables à été écrit. Celui-ci va constituer dans un premier temps en la destruction des tables et de leurs contraintes dans le cas à l'aide d'un drop table. Il va ensuite permettre de construire ces tables en affectant les clefs primaires et étrangères appropriés à chaque table."
      ]
    },
    {
      "metadata": {
        "id": "XTdZBN1V3KKZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "------Destruction des tables\n",
        "\n",
        "drop table plant cascade ;\n",
        "drop table phenotype cascade ;\n",
        "drop table  boite cascade ;\n",
        "drop table  milieu cascade ;\n",
        "drop table  genotype cascade ;\n",
        "drop table  gene cascade ;\n",
        "drop table  cv cascade ;\n",
        "drop table cvterm cascade ;\n",
        "drop table  features cascade ;\n",
        "\n",
        "--------------------------------------------------Creations tables--------------------------------------------\n",
        "\n",
        "----table plant\n",
        "create table plant (plant_id varchar(10) not null, primary key (plant_id), grouping int not null, plant_group int not null);\n",
        "\n",
        "---table phenotype\n",
        "create table phenotype (organism_id serial,primary key (organism_id), ShootArea real,  distFromHypocotyl real,  chlorophyll real, \n",
        "\t\t\t\t\t\tRoot_area real, tortuosity real, PR_lenght real, LR_lenght real,\n",
        "\t\t\t\t\t\tplant_id varchar(10) not null, constraint ph_fk foreign key (plant_id) references plant (plant_id) on delete cascade INITIALLY DEFERRED);\n",
        "\n",
        "----table boite\n",
        "create table boite (id_boite int, primary key(id_boite), plate varchar (20) not null, plant_id varchar (10), constraint b_fk foreign key (plant_id) references plant (plant_id) on delete cascade INITIALLY DEFERRED);\n",
        "\n",
        "----table milieu\n",
        "create table milieu(id_milieu int, primary key(id_milieu), type varchar (150) not null, \n",
        "\t\t\t id_boite int not null, constraint m_fk foreign key(id_boite) references boite(id_boite) on delete cascade INITIALLY DEFERRED);\n",
        "\n",
        "----table genotype\n",
        "create table gene(gene_id int not null, primary key(gene_id), gene_name varchar(20), est_mutant boolean);\n",
        "\n",
        "----table gene\n",
        "create table genotype(gene_id int not null, plant_id varchar(10), \n",
        "\t\t\t\t\tconstraint geno_pk primary key (gene_id, plant_id), \n",
        "\t\t\t\t\tconstraint gen_fk foreign key (gene_id) references gene(gene_id) on delete cascade INITIALLY DEFERRED, constraint plant_fk foreign key (plant_id) references plant(plant_id) on delete cascade INITIALLY DEFERRED);\n",
        "\n",
        "---------------Tables Ontologies-----------\n",
        "\n",
        "----table cv\n",
        "create table cv(cv_id serial not null, primary key (cv_id), name varchar(255) not null, definition text, constraint cv_c1 unique (name));\n",
        "\n",
        "----table cvterm\n",
        "create table cvterm(cvterm_id serial not null,\n",
        "    primary key (cvterm_id),\n",
        "    cv_id int not null,\n",
        "    constraint cvt_fk foreign key (cv_id) references cv (cv_id) on delete cascade INITIALLY DEFERRED ,\n",
        "    name varchar(1024) not null,\n",
        "    definition text);\n",
        "\n",
        "\n",
        "create table features(feature_id serial not null,\n",
        "    primary key (feature_id),  organism_id int not null,\n",
        "    constraint f1_fk foreign key (organism_id) references phenotype (organism_id) on delete cascade INITIALLY DEFERRED,\n",
        "    name varchar(20),\n",
        "    uniquename text not null, type_id int not null,\n",
        "    constraint f2_fk foreign key (type_id) references cvterm (cvterm_id) on delete cascade INITIALLY DEFERRED);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-BawZan3Pej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Afin de générer les tables nécessaires à l'ontologie, le module cv de Chado à été utilisé. Je me rends compte cependant à l'écriture de ce rapport que  j'ai mal compris et mal utilisé ce module cv, notamment en n'utilisant pas la table cv_term relationship."
      ]
    },
    {
      "metadata": {
        "id": "Uz_PCK-y3Te6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Insertions des données dans les tuples"
      ]
    },
    {
      "metadata": {
        "id": "mFVSNkba35As",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Afin de ne pas avoir à insérer les données issues du document csv qui nous a été fourni manuellement dans nos tuples une réorganisation de celles-ci a été effectué. Celle-ci ont ainsi été redistribuées sur plusieurs fichier csv correspondant chacun à une table donnée. On peut ensuite insérer les données contenues dans ces fichier dans nos tuples à l'aide de la commande \\copy . \n",
        "\n",
        "Ci-dessous le script de remplissage des tuples:"
      ]
    },
    {
      "metadata": {
        "id": "Kc9EU7JO384D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "-----------------------CREATION DES TUPLES-------------------------------\n",
        "\n",
        "----------------Plant-------------------------------\n",
        "\n",
        "\\copy plant FROM 'plant.csv' delimiter ',' CSV HEADER;\n",
        "\n",
        "-----------------Phenotypes--------------------------\n",
        "\n",
        "\\copy phenotype FROM 'phenotype.csv' delimiter ',' CSV HEADER;\n",
        "\n",
        "-----------------boite------------------------\n",
        "\n",
        "\\copy boite FROM 'boite.csv' delimiter ',' CSV HEADER;\n",
        "\n",
        "-----------------Milieu-------------------------\n",
        "\n",
        "\\copy milieu FROM 'milieu.csv' delimiter ',' CSV HEADER;\n",
        "\n",
        "-----------------gene-------------------------------\n",
        "\n",
        "\\copy gene FROM 'gene.csv' delimiter ',' CSV HEADER;\n",
        "\n",
        "\n",
        "-----------------genotype------------------------\n",
        "\n",
        "\\copy genotype FROM 'genotype.csv' delimiter ',' CSV HEADER;\n",
        "\n",
        "------------------cv--------------------------------\n",
        "\n",
        "insert into cv values ( DEFAULT, 'http://purl.obolibrary.org/obo/pato.owl' , 'PATO');\n",
        "insert into cv values ( DEFAULT, 'http://purl.obolibrary.org/obo/po.owl' , 'PO');\n",
        "insert into cv values ( DEFAULT, 'http://purl.obolibrary.org/obo/flopo.owl', 'FLOPO');\t\n",
        "insert into cv values ( DEFAULT, 'http://purl.obolibrary.org/obo/to.owl', 'TO');\n",
        "insert into cv values ( DEFAULT, 'Arabidopsis Phenotype Ontology','APO');\n",
        "\n",
        "------------------cvterm----------------------------\n",
        "\n",
        "insert into cvterm values (DEFAULT, 5, 'Root Lenght', 'a root lenght (FLOPO_0009325) which is part of a primary root (PO_0020127');\n",
        "insert into cvterm values (DEFAULT, 5, 'Root Lenght', 'a root lenght (FLOPO_0009325) which is part of a lateral root (PO_0020121');\n",
        "insert into cvterm values (DEFAULT, 5, 'area', 'an area (PATO_0001323 which is part of the shoot axis (PO_0025029)');\n",
        "insert into cvterm values (DEFAULT, 5, 'area', 'an area (PATO_0001323) which is part of the root (PO_0009005)');\n",
        "insert into cvterm values (DEFAULT, 5, 'distance', 'a distance(PATO_000040) between roots (PO_0009005) and hypocotyl (PO_0020100)');\n",
        "insert into cvterm values (DEFAULT, 4, 'chlorophyll contents', 'Measures the chlorophyll content in a green tissue. Includes both chlorophyll-a and chlorophyll-b. Chlorophyll is the green pigment found in plants.');\n",
        "insert into cvterm values (DEFAULT, 5, 'curvature', 'a curvature (PATO_0001591) which is part of roots (PO_0009005)');\n",
        "\n",
        "------------------features--------------------------\n",
        "\n",
        "insert into features values (DEFAULT, 1, 'PR_lenght', 'APO_000001', 1 );\n",
        "insert into features values (DEFAULT, 1 , 'LR_lenght', 'APO_000002', 2);\n",
        "insert into features values (DEFAULT, 1 ,'ShootArea', 'APO_000003',3);\n",
        "insert into features values (DEFAULT, 1 , 'RootArea', 'APO_000004',4);\n",
        "insert into features values (DEFAULT, 1 , 'DistanceFromHypocotyl', 'APO_000005',5);\n",
        "insert into features values (DEFAULT, 1 , 'Chlorophylle','TO_0000495',6);\n",
        "insert into features values (DEFAULT, 1 , 'Tortuosity', 'APO_000006', 7);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IXDbg-GC4Ar8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Requêtes"
      ]
    },
    {
      "metadata": {
        "id": "ZNZgL3Pg4Fck",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Quelques requêtes ont ensuite été écrites afin de tester la base de données générée. Ces requêtes ont été regroupées dans le script ci-dessous. "
      ]
    },
    {
      "metadata": {
        "id": "IgInUPg24F-x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "------Recupère l'id des plants ayant un génotype mutant et affiche la longueur de leur racines primaires et l'ontologie associée---------------- \n",
        "\n",
        "select ph.plant_id,ph.PR_lenght, f.name, f.uniquename,p.grouping, ct.definition \n",
        "from phenotype ph , features f, cvterm ct, genotype gt, gene g, plant p \n",
        "where g.gene_id = gt.gene_id and gt.plant_id = p.plant_id and p.plant_id= ph.plant_id and g.est_mutant = TRUE and f.name= 'PR_lenght' and f.type_id = ct.cvterm_id;\n",
        "\n",
        "\n",
        "\n",
        "---------------Compare l'effet des mutations sur l'entrelacement des racines--------------\n",
        "\n",
        "select g.gene_name, count(p.grouping)  \n",
        "from gene g, plant p, genotype gt \n",
        "where g.gene_id = gt.gene_id and gt.plant_id = p.plant_id and p.grouping = 1 group by g.gene_name;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "-----------Observe le potentiel effet du milieu sur la taille moyenne de l'aire racinaire--------- \n",
        "\n",
        "select m.type, avg(ph.Root_area)\n",
        "from milieu m, boite b, plant p, phenotype ph\n",
        "where m.id_boite = b.id_boite and b.plant_id = p.plant_id and p.plant_id = ph.plant_id \n",
        "group by m.type;\n",
        "\n",
        "-----------------Affiche l'id de tout les individus sauf ceux Col 0-------------------------\n",
        "\n",
        "select p.plant_id from plant p, genotype gt,gene g\n",
        "where g.gene_id = gt.gene_id and gt.plant_id = p.plant_id\n",
        "EXCEPT\n",
        "select gt.plant_id from plant p, gene g , genotype gt\n",
        "where g.gene_id = gt.gene_id and gt.plant_id = p.plant_id and g.gene_name = 'Col_0';\n",
        "\n",
        "----------------Affiche \n",
        "\n",
        "select f.name, f.uniquename,ct.name, ct.definition  from features f, cvterm ct, cv c\n",
        "where c.cv_id = ct.cv_id and ct.cvterm_id = f.type_id and c.definition ='APO';"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CCOwez_p5FI2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ces  requêtes m'ont permis de me rendre compte que certains éléments de la base de donnée auraient mérités à être pensé autrement afin de pouvoir faire des requêtes plus précise et intéressantes au niveau de l'ontologie."
      ]
    },
    {
      "metadata": {
        "id": "0iiF1K6YKhgj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n"
      ]
    },
    {
      "metadata": {
        "id": "HE4Lo1I5K0N9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ainsi nous avons été en mesure de générer une base de donnée permettant de faire des requêtes pour la consultation et potentiellement l'interprétation des résultats obtenus par les M1 BFP . Cette base de données permet aussi de consulter les relations d'ontologies des phénotypes mesurés. Cependant cette ontologie n'a pas été implémenté de manière optimale par manque de comprhéension et de temps pour rattraper les erreurs. Les séquences nucléiques des gènes o,t pu être récupéreés depuis le NCBI puis elles ont pu être analysées àl'aide de BioPython pour nous fournir des informations qui auraient pu être utilisées dans notre base de données. "
      ]
    }
  ]
}